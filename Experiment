import pandas as pd

# Assuming your dataset is stored in a DataFrame called df
# Replace 'Counterparty Name', 'CCY', and 'ValueDate' with the actual column names in your dataset

# Group by the specified columns and count occurrences
counts = df.groupby(['Counterparty Name', 'CCY', 'ValueDate']).size()

# Filter to keep only rows where the combination repeats twice
filtered_df = df[df.apply(lambda row: counts[(row['Counterparty Name'], row['CCY'], row['ValueDate'])] == 2, axis=1)]

# Now, filtered_df contains the rows where the specified combination repeats twice




import pandas as pd

# Assuming your dataset is stored in a DataFrame called df
# Replace 'Key' and 'Net' with the actual column names in your dataset

# Group by the unique key
grouped = df.groupby('Key')

# Define a function to check the conditions and drop rows accordingly
def filter_rows(group):
    if (group['Net'].eq(0).any()) or (group['Net'].prod() > 0):
        return group.drop(group.index)
    return group

# Apply the function to each group and concatenate the results
filtered_df = pd.concat([filter_rows(group) for _, group in grouped])

# Now, filtered_df contains the DataFrame with rows dropped as per the conditions




import pandas as pd

# Assuming your DataFrame is called df and contains columns 'Key' and 'Net'

# Calculate the absolute values of the 'Net' column
df['Absolute_Net'] = df['Net'].abs()

# Get the index of the row with the lowest absolute value for each key
idx_to_keep = df.groupby('Key')['Absolute_Net'].idxmin()

# Filter the DataFrame to keep only the rows with the lowest absolute value for each key
filtered_df = df.loc[idx_to_keep]

# Drop the 'Absolute_Net' column if you no longer need it
filtered_df.drop('Absolute_Net', axis=1, inplace=True)

# Now, filtered_df contains only the rows with the lowest absolute value of 'Net' for each key


import pandas as pd

# Assuming your dataset is stored in a DataFrame called df
# Replace 'Counterparty Name', 'CCY', 'Value Date', and 'Net' with the actual column names in your dataset

# Pivot the DataFrame
pivot_df = df.pivot_table(index=['Counterparty Name', 'CCY'], columns='Value Date', values='Net', aggfunc='first')

# Reset index to make 'Counterparty Name' and 'CCY' regular columns
pivot_df.reset_index(inplace=True)

# Now, pivot_df contains the 'Value Date' unique values as columns with other columns unchanged
