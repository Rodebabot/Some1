import pandas as pd
from collections import Counter
import re
from nltk.util import ngrams

# Ensure 'Days Spent' column is numeric
action['Days Spent'] = pd.to_numeric(action['Days Spent'], errors='coerce')

# Function to clean the text
def clean_text(text):
    text = re.sub(r'[^A-Za-z\s]', '', text)  # Remove special characters
    text = re.sub(r'\s+', ' ', text).strip()  # Remove extra spaces
    return text

# Function to get n-grams
def get_ngrams(text, n):
    words = text.split()
    n_grams = ngrams(words, n)
    return [' '.join(gram) for gram in n_grams]

# Function to find top 5 phrases excluding subsets
def get_top_phrases(phrases_counter, top_n=5):
    sorted_phrases = [phrase for phrase, count in phrases_counter.most_common()]
    top_phrases = []
    
    for phrase in sorted_phrases:
        if len(top_phrases) >= top_n:
            break
        if not any(phrase in bigger_phrase for bigger_phrase in top_phrases):
            top_phrases.append(phrase)
    
    return top_phrases

# Dictionary to store results
counterparty_phrase_analysis = {}

# List of specified ROCs
specified_rocs = [
    'counterpartytoaction', 
    'cptytoactioneconomicbreak', 
    'cptytoactiontemplatenegotiation'
]

# Filter the dataframe to include only the specified ROCs
filtered_action = action[action['ROC'].isin(specified_rocs)]

for roc in specified_rocs:
    comments = filtered_action[filtered_action['ROC'] == roc]
    counterparties = comments['Counterparty Name'].unique()
    
    for counterparty in counterparties:
        relevant_comments = comments[comments['Counterparty Name'] == counterparty]
        relevant_comments = relevant_comments['Latest Confirmation Status Comment'].dropna().apply(clean_text)
        
        all_phrases = []
        for comment in relevant_comments:
            all_phrases.extend(get_ngrams(comment, 4))  # Extracting 4-grams
            all_phrases.extend(get_ngrams(comment, 5))  # Extracting 5-grams
            all_phrases.extend(get_ngrams(comment, 6))  # Extracting 6-grams
        
        phrases_counter = Counter(all_phrases)
        top_phrases = get_top_phrases(phrases_counter)
        
        # Calculate the average Days Spent for each of the top phrases
        phrase_days_spent = {}
        for phrase in top_phrases:
            matching_rows = comments[comments['Latest Confirmation Status Comment'].str.contains(phrase)]
            average_days_spent = matching_rows['Days Spent'].mean()
            phrase_days_spent[phrase] = average_days_spent
        
        if roc not in counterparty_phrase_analysis:
            counterparty_phrase_analysis[roc] = {}
        counterparty_phrase_analysis[roc][counterparty] = phrase_days_spent

# Print the results
for roc, counterparty_phrases in counterparty_phrase_analysis.items():
    print(f"Top phrases where counterparties are getting stuck for ROC {roc}:")
    for counterparty, phrase_info in counterparty_phrases.items():
        print(f"\nCounterparty: {counterparty}")
        for phrase, avg_days in phrase_info.items():
            print(f"Phrase: {phrase} - Average Days Spent: {avg_days:.2f}")

# Save the results to a CSV file
results = []

for roc, counterparty_phrases in counterparty_phrase_analysis.items():
    for counterparty, phrase_info in counterparty_phrases.items():
        for phrase, avg_days in phrase_info.items():
            results.append({'ROC': roc, 'Counterparty': counterparty, 'Phrase': phrase, 'Average Days Spent': avg_days})

results_df = pd.DataFrame(results)
results_df.to_csv('/mnt/data/top_phrases_per_counterparty.csv', index=False)
